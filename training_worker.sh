#!/bin/bash

## chmod +x training_worker.sh
# ä½¿ç”¨æ–¹å¼ï¼šbash training_worker.sh <GPU_ID>
# ä¾‹å¦‚ï¼šbash training_worker.sh 0

GPU_ID=$1
QUEUE_FILE="training_queue.txt"
LOCK_FILE="training_queue.lock"

# --- è¨­å®šå€ ---
PYTHON_BIN="/mnt/HDD3/miayan/paper/envs/scriblit/bin/python3.10"
SCRIPT_PATH="train.py"
VALIDATION_FILE="custom_unet.pth"
CHECK_INTERVAL=30
# é¡¯å­˜é–€æª» (MB)ï¼šå¦‚æœ GPU å³ä½¿æœ‰ process ä½†åƒå°‘æ–¼é€™å€‹æ•¸å­—ï¼Œè¦–ç‚ºç©ºé–’ (å¯æ¶)
MEM_THRESHOLD=10000 

if [ -z "$GPU_ID" ]; then
    echo "âŒ è«‹æŒ‡å®š GPU ID (ä¾‹å¦‚: ./training_worker.sh 0)"
    exit 1
fi

# è‡ªå‹•è¨ˆç®— Port (é¿å…é›™å¡è¡çª)
CURRENT_PORT=$((29500 + GPU_ID))
ACC_ARGS="--main_process_port=$CURRENT_PORT"

# ================= æ ¸å¿ƒå‡½å¼ =================

# 1. æª¢æŸ¥ GPU ç‹€æ…‹ (å›å‚³: "BUSY_MY", "BUSY_OTHER", "FREE")
check_gpu_status() {
    # å–å¾—è©² GPU ä¸Šæ‰€æœ‰ process çš„ PID å’Œ ä½¿ç”¨è€…ID
    # æ ¼å¼: PID, UID, USED_MEMORY
    local proc_info=$(nvidia-smi -i $GPU_ID --query-compute-apps=pid,used_memory --format=csv,noheader,nounits)

    if [ -z "$proc_info" ]; then
        echo "FREE"
        return
    fi

    # è®€å–æ¯ä¸€è¡Œ Process
    local is_free="FREE"
    
    while IFS=, read -r pid used_mem; do
        # æª¢æŸ¥æ˜¯ä¸æ˜¯æˆ‘åœ¨è·‘ train.py
        if ps -p $pid -o args= 2>/dev/null | grep -q "$SCRIPT_PATH"; then
            # æª¢æŸ¥ owner æ˜¯ä¸æ˜¯æˆ‘
            local owner=$(ps -o user= -p $pid)
            if [ "$owner" == "$USER" ]; then
                echo "BUSY_MY"
                return
            fi
        fi

        # å¦‚æœä¸æ˜¯æˆ‘çš„ train.pyï¼Œæª¢æŸ¥é¡¯å­˜ä½”ç”¨
        # å»é™¤ç©ºç™½
        used_mem=$(echo $used_mem | xargs)
        if [ "$used_mem" -gt "$MEM_THRESHOLD" ]; then
            is_free="BUSY_OTHER"
        fi
    done <<< "$proc_info"

    echo "$is_free"
}

# 2. åŸ·è¡Œç›£æ§èˆ‡æ•‘æ´ (Watchdog)
run_watchdog() {
    local config_path=$1
    local output_dir=$2
    local target_ckpt=$3
    local target_dir="./$output_dir/$target_ckpt"

    echo "ğŸ›¡ï¸  é€²å…¥ç›£æ§æ¨¡å¼ ($target_ckpt)..."

    while true; do
        # æª¢æŸ¥æ˜¯å¦é‚„åœ¨è·‘ (åªçœ‹æˆ‘è‡ªå·±çš„ process)
        local my_running=false
        local pids=$(pgrep -u "$USER" -f "$SCRIPT_PATH")
        
        # é€™è£¡è¦éæ¿¾ï¼Œç¢ºä¿è©² PID çœŸçš„æ˜¯è·‘åœ¨ç›®å‰é€™å¼µ GPU ä¸Š
        for pid in $pids; do
             # ç”¨ nvidia-smi æŸ¥é€™å€‹ pid æœ‰æ²’æœ‰ç”¨é€™å¼µå¡
             if nvidia-smi -i $GPU_ID --query-compute-apps=pid --format=csv,noheader | grep -q "$pid"; then
                 my_running=true
                 break
             fi
        done

        if [ "$my_running" = true ]; then
            echo -ne "â³ GPU $GPU_ID | æ­£åœ¨åŸ·è¡Œ: $output_dir | $(date +'%H:%M')\r"
            sleep $CHECK_INTERVAL
            continue
        fi

        # Process åœäº†ï¼Œé©—æ”¶
        echo ""
        echo "âš ï¸  GPU $GPU_ID Process åœæ­¢ï¼æª¢æŸ¥çµæœ..."

        if [ -d "$target_dir" ] && [ -f "$target_dir/$VALIDATION_FILE" ]; then
            echo "âœ… ä»»å‹™å®Œæˆï¼"
            return 0 # æˆåŠŸï¼Œè¿”å›ä¸»è¿´åœˆå»é ˜ä¸‹ä¸€å€‹ä»»å‹™
        else
            echo "âŒ ä»»å‹™æœªå®Œæˆ (OOMæˆ–ä¸­æ–·)ã€‚"
            echo "ğŸ”„ 10ç§’å¾ŒåŸåœ°æ•‘æ´é‡å•Ÿ..."
            sleep 10
            
            mkdir -p "$output_dir"
            log_file="./$output_dir/train_log_$(date +%Y%m%d_%H%M).txt"
            
            FULL_CMD="export PYTHONUNBUFFERED=1; CUDA_VISIBLE_DEVICES=$GPU_ID accelerate launch $ACC_ARGS $SCRIPT_PATH --config $config_path --output_dir $output_dir"
            
            echo "åŸ·è¡Œ: $FULL_CMD"
            nohup bash -c "$FULL_CMD" > "$log_file" 2>&1 &
            
            sleep 20
            echo "ğŸ‘€ å·²é‡å•Ÿï¼Œç¹¼çºŒç›£æ§..."
        fi
    done
}

# ================= ä¸»æµç¨‹ =================

echo "ğŸš€ å•Ÿå‹• GPU $GPU_ID æ™ºæ…§å·¥äºº (é–¾å€¼: ${MEM_THRESHOLD}MB)"

while true; do
    STATUS=$(check_gpu_status)

    if [ "$STATUS" == "BUSY_MY" ]; then
        echo "ğŸ” ç™¼ç¾ GPU $GPU_ID å·²ç¶“æœ‰æˆ‘çš„ä»»å‹™åœ¨è·‘ï¼ç›´æ¥æ¥æ‰‹ç›£æ§..."
        # é€™è£¡æ¯”è¼ƒå°·å°¬ï¼Œå› ç‚ºæˆ‘å€‘ä¸çŸ¥é“ç¾åœ¨è·‘çš„æ˜¯å“ªå€‹ config
        # ä½†æˆ‘å€‘å¯ä»¥ã€Œç›²ç›®ç›£æ§ã€ï¼šåªè¦ process æ­»æ‰ä¸” queue è£¡æœ‰æ±è¥¿ï¼Œå°±å‡è¨­èˆŠçš„è·‘å®Œäº†
        # ç‚ºäº†å®‰å…¨ï¼Œé€™è£¡æˆ‘å€‘åšä¸€å€‹ç°¡å–®çš„ç­‰å¾…è¿´åœˆï¼Œç›´åˆ°å®ƒæ­»æ‰
        while [ "$(check_gpu_status)" == "BUSY_MY" ]; do
            echo -ne "â³ ç›£æ§æ—¢æœ‰ä»»å‹™ä¸­... $(date +'%H:%M:%S')\r"
            sleep 30
        done
        echo ""
        echo "âœ… æ—¢æœ‰ä»»å‹™çµæŸ (æˆ–ä¸­æ–·)ã€‚æº–å‚™é ˜å–æ–°ä»»å‹™..."
        continue

    elif [ "$STATUS" == "BUSY_OTHER" ]; then
        echo -ne "â›” GPU $GPU_ID è¢«å…¶ä»–äººä½”ç”¨ (VRAM > ${MEM_THRESHOLD}MB)ï¼Œç­‰å¾…ä¸­... $(date +'%H:%M:%S')\r"
        sleep 60
        continue
    fi

    # === STATUS == FREE (å¯ä»¥é ˜ä»»å‹™äº†) ===
    
    # å» queue æ¶ä»»å‹™
    NEXT_TASK=""
    (
        flock -x 200
        if [ -s "$QUEUE_FILE" ]; then
            NEXT_TASK=$(head -n 1 "$QUEUE_FILE")
            sed -i '1d' "$QUEUE_FILE"
        fi
    ) 200>"$LOCK_FILE"

    if [ -z "$NEXT_TASK" ]; then
        echo -ne "ğŸ’¤ ä»»å‹™æ± ç©ºäº†ï¼ŒGPU $GPU_ID å¾…æ©Ÿä¸­... $(date +'%H:%M:%S')\r"
        sleep 60
    else
        echo "ğŸ‰ GPU $GPU_ID æ¶åˆ°ä»»å‹™ï¼"
        IFS="|" read -r q_cfg q_out q_ckpt <<< "$NEXT_TASK"
        
        # 1. å•Ÿå‹•ä»»å‹™
        mkdir -p "$q_out"
        log_file="./$q_out/train_log_$(date +%Y%m%d_%H%M).txt"
        
        FULL_CMD="export PYTHONUNBUFFERED=1; CUDA_VISIBLE_DEVICES=$GPU_ID accelerate launch $ACC_ARGS $SCRIPT_PATH --config $q_cfg --output_dir $q_out"
        
        echo "ğŸš€ å•Ÿå‹•: $q_out"
        nohup bash -c "$FULL_CMD" > "$log_file" 2>&1 &
        sleep 20 # ç­‰å¾…å•Ÿå‹•
        
        # 2. é€²å…¥ç›£æ§ (ç›´åˆ°é€™å€‹ä»»å‹™åšå®Œ)
        run_watchdog "$q_cfg" "$q_out" "$q_ckpt"
    fi
done